<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>Chapter 11</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="./css/reveal.css">
    <link rel="stylesheet" href="./css/theme/whiteNight.css" id="theme">
    <!-- <link rel="stylesheet" href="./css/print/pdf.css"> -->
  </head>
  
  <style type="text/css">
    section { text-align: left; }
  </style>
  
  <body>
    <div class="reveal">
      <div class="slides">

	<section>
	  <h3>Modeling</h3>
	  <center>
	    <a href="https://en.wikipedia.org/wiki/Linear_regression">
	      <img src="./images/linear_regression.jpg" alt=" " style="width: 70%;max-height: 100%;object-fit: contain;Float: center" />
	    </a>
	  </center>
	  <div style="width: 100%; overflow: hidden;">
	    <div style="width: 400px; float: left;">
	      <medium>
		<a href="http://www.pages.drexel.edu/~jnl47/">Jeremy Leipzig</a><br>
	      </medium>
	      <small>
				
		Department of Information Science <br>
		College of Computing and Informatics <br>
		Drexel University
	      </small>
	    </div>
	    <div style="margin-left: 420px;">
	      <medium>
		<a href="index.html">Introduction to data science</a><br>
	      </medium>
	      <small>
		Spring, 2019 <br>
		<a href="syllabus.pdf">Syllabus</a><br>
	      </small>
	    </div>
	  </div>
	</section>

	<section>
	  <h3>Some themes</h3>

	  <li class='fragment'>
	    Modeling is heavy on mathematics and statistics.
	  </li>
	  
	  <li class='fragment'>
	    Model selection is guided by many factors,
	  </li>

	  <li class='fragment'>
	    and is preceded by exploratory data analysis.
	  </li>	  

	  <li class='fragment'>
	    Theoretical relevance can make a model highly valuable,
	  </li>	  
	  
	  <li class='fragment'>
	    but sometimes it's all about performance product quality,
	  </li>

	  <li class='fragment'>
	    balancing bias and variance as best possible.
	  </li>

	</section>
	
	<section>
	  <h3>What is modeling?</h3>

	  <li class='fragment'>
	    The real world is a messy place,
	  </li>
	  <li class='fragment'>
	    but this is where data comes from.
	  </li>
	  <li class='fragment'>
	    While data might be generated by a &quot;true&quot; mechanism,
	  </li>	  
	  <li class='fragment'>
	    it may not be known, and exist with interference and noise.
	  </li>
	  <li class='fragment'>
	    Some modeling seeks to simulate real world phenomena,
	  </li>
	  <li class='fragment'>
	    but for us will exist in the context of explaining data,
	  </li>
	  <li class='fragment'>
	    and &quot;fitting it&quot; to identify and predict real-world processes.
	  </li>
	</section>

	<section>
	  <h3>The role of mathematics</h3>

	  <li class='fragment'>
	    Mathematics is integral to modeling,
	  </li>
	  <li class='fragment'>
	    as it provides tools and frameworks for abstraction.
	  </li>
	  <li class='fragment'>	    
	    While models might have physical or social foundations,
	  </li>
	  <li class='fragment'>
	    these must be expressed mathematically to be applied.
	  </li>	  
	  <li class='fragment'>
	    A mathematical model might use simple, high school algebra,
	  </li>
	  <li class='fragment'>
	    or any part of calculus or matrix algebra as a framework.
	  </li>
	</section>

	<section>
	  <h3>Calculus</h3>

	  <li class='fragment'>
	    Calculus is all about rates of change and accumulation.
	  </li>	  	  

	  <li class='fragment'>
	    This becomes very important when approaching optimization,
	  </li>	  	  

	  <li class='fragment'>
	    e.g., when error is minimized for a parameter's estimation.
	  </li>	  	  

	  <li class='fragment'>
	    However, calculus is a continuous (smooth) science
	  </li>

	  <li class='fragment'>
	    and measurements and computations are always discrete,
	  </li>  
	  
	  <li class='fragment'>
	    so the day-to-day value for DS is largely with intuition
	  </li>

	  <li class='fragment'>
	    and model development or analysis, instead of application.
	  </li>  
	</section>

	<section>
	  <h3>Differential calculus is about rates (slopes)</h3>
	  <center>
	    <div style="float: left">
	      <a href="https://en.wikipedia.org/wiki/Calculus#Differential_calculus">
		<img src="./images/Sec2tan.gif" style="width: 100%; max-height: 100%;" />
	      </a>
	    </div>	    
	    <div style="position:absolute; top: 27.5%; left: 67.5%; text-align: left;">
	      The derivative fâ€²(x) of a curve at a point is the slope of the line tangent to that curve at that point.
	      This slope is determined by considering the limiting value of the slopes of secant lines.
	    </div>
	  </center>
	</section>

	<section>
	  <h3>Integral calculus is about accumulation</h3>
	  <center>
	    <div style="float: left">
	      <a href="https://en.wikipedia.org/wiki/Calculus#Integral_calculus">
		<img src="./images/region_under_curve.jpg" style="width: 100%;max-height: 100%;" />
	      </a>
	    </div>
	    <div style="position:absolute; top: 27.5%; left: 67.5%; text-align: left;">
	      Integration can be thought of as measuring the area under a curve, defined by f(x), between two points (here a and b).
	    </div>
	  </center>
	</section>
	
	<section>
	  <h3>Required readings</h3>
	  
	  If you have never seen calculus, please read 
	  sections <a href="https://en.wikipedia.org/wiki/Calculus#Differential_calculus">2.2</a>
	  and <a href="https://en.wikipedia.org/wiki/Calculus#Integral_calculus">2.4</a>
	  from Wikipedia's article on the topic,
	  but do not worry if you don't understand the algebraic details,
	  i.e., just focus on gaining an intuition for rates and accumulation.

	</section>

	<section>
	  <h3>Linear algebra</h3>
	  
	  <li class='fragment'>
	    Linear algebra is all about equations and solutions,
	  </li>	  
	  <li class='fragment'>
	    with restrictions on the types of operations considered,
	  </li>
	  <li class='fragment'>
	    i.e., only multiplication and addition (making things linear),
	  </li>
	  <li class='fragment'>
	    and extreme generality for many dimensions.
	  </li>
	  <li class='fragment'>
	    For data representation this is an important framework,
	  </li>
	  <li class='fragment'>
	    e.g., raster images are matrices of color intensities.
	  </li>	   
	  <li class='fragment'>
	    In algorithms, linear algebra plays a central role, too,
	  </li>
	  <li class='fragment'>
	    e.g., Google's search algorithm is a matrix multiplication!
	  </li>
	</section>
	
	<section>
	  <h3>PageRank is matrix multiplication</h3>
	  <center>
	    <a href="http://www.slideshare.net/liyifancolumbia/google-page-rank-33716635">
	      <img src="./images/google-page-rank.jpg" alt=" " style="width: 70%;max-height: 100%;object-fit: contain;Float: center" />
	    </a>
	  </center>
	</section>

	<section>
	  <h3>Required videos</h3>
	  If you've never had linear algebra, please watch the first four videos in this series:
	  <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">the essence of linear algebra</a>, 
	  and once again, don't worry so much about the details,
	  but focus on gaining an intuition for the nature of the subject.
	</section>

	<section>
	  <h3>Calculus vs. linear algebra</h3>

	  <li class='fragment'>
	    Calculus usually gets extreme emphasis in math education.
	  </li>
	  <li class='fragment'>
	    However, there is contention over which is more important.
	  </li>
	  <li class='fragment'>
	    This is true, with perhaps more emphasis in data science,
	  </li>
	  <li class='fragment'>
	    where many attest its usefulness over calculus.
	  </li>
	  <li class='fragment'>
	    Is this true, or simply backlash against historical emphasis?
	  </li>
	  <li class='fragment'>
	    Whether either is intuitively grounding or explicitly useful,
	  </li>
	  <li class='fragment'>
	    neither branch of math should really be left out entirely,
	  </li>
	  <li class='fragment'>
	    i.e., a data scientist is best off understanding both.
	  </li>
	  <li class='fragment'>
	    Required reading: <a href="http://www.wsj.com/articles/calculus-is-so-last-century-1457132991">Calculus is so last century.</a>
	  </li>	  
	</section>	
	
	<section>
	  <h3>Probability and statistics</h3>
	  <li class='fragment'>
	    Probability and statistics are focused on quantifying chance.
	  </li>
	  <li class='fragment'>
	    Probabilistic models can be theorized to understand data,
	  </li>
	  <li class='fragment'>
	     and statistics are computed from data to hypothesize models.
	  </li>
	  <li class='fragment'>
	    Probability and statistics are largely inseparable,
	  </li>
	  <li class='fragment'>
	    and they use both calculus and linear algebra for modeling.
	  </li>
	  <li class='fragment'>
	    Historically, a lot of statistics were developed as normal,
	  </li>
	  <li class='fragment'>
	    i.e., for physical, height-weight, bell-shaped distributions,
	  </li>
	  <li class='fragment'>
	    but in fact many real-world distributions are much wilder,
	  </li>	  
	  <li class='fragment'>
	    like market movements, community sizes, and disaster scales.
	  </li>
	  <li class='fragment'>
	    It's important have a broad view of statistical concepts.
	  </li>	  
	</section>

	<section>
	  <h3>Required reading</h3>
	  If you've never had any probability and/or statistics, please read
	  <a href="https://betterexplained.com/articles/a-brief-introduction-to-probability-statistics/">this post.</a>
	</section>

	<section>
	  <h3>Data science vs. statistics</h3>
	  <li class='fragment'>
	    Historically, statistics is thought of as the science of data.
	  </li>
	  <li class='fragment'>
	    Does that mean data science is overriding statistics?
	  </li>
	  <li class='fragment'>
	    No! Once again, data science is all about a collision of skills.
	  </li>
	  <li class='fragment'>
	    Statisticians can be data scientists (and vice-versa),
	  </li>
	  <li class='fragment'>
	    and data science can't exist without statistics, but
	  </li>
	  <li class='fragment'>
	    this is not true for CS, or management and database systems.
	  </li>
	  <li class='fragment'>
	    Contentions around disciplinary encroachment are unfortunate,
	  </li>
	  <li class='fragment'>
	    and can be met with reverence and respect,
	  </li>
	  <li class='fragment'>
	    which starts with understanding what others do.
	  </li>
	  <li class='fragment'>
	    Required reading: <a href="https://blog.mixpanel.com/2016/03/30/this-is-the-difference-between-statistics-and-data-science/">Statistics vs. data science</a>
	  </li>	  

	</section>
	
	<section>
	  <h3>Regression</h3>

	  <li class='fragment'>
	    Regression is all about fitting shapes to data.
	  </li>
	  <li class='fragment'>
	    e.g., fitting a line to a cloud of points,
	  </li>
	  <li class='fragment'>
	    or a distributional model to empirical results.
	  </li>	  
	  <li class='fragment'>
	    Two main components to running a regression are:
	  </li>	  	  
	  <li class='fragment'>
	    Parameterizations, and objective functions.
	  </li>
	  <li class='fragment'>
	    Parameterizations describe model specifics, e.g., slope,
	  </li>
	  <li class='fragment'>
	    and objective functions describe how well a model fits.
	  </li>

	</section>

	<section>
	  <h3>Objective functions</h3>

	  <li class='fragment'>
	    An objective function is a quantity that modeling optimizes,
	  </li>
	  <li class='fragment'>
	    e.g., sum of squares error, precision, or recall.
	  </li>
	  <li class='fragment'>
	    Objective functions can either be maximized or minimized,
	  </li>	  
	  <li class='fragment'>
	    and sometimes there can be more than one.
	  </li>	  	  
	  <li class='fragment'>
	    Convex optimization is a special case for objective functions
	  </li>
	  <li class='fragment'>
	    where there is a guaranteed &quot;best case.&quot;
	  </li>
	  <li class='fragment'>
	    Unfortunately, not all algorithms result in convex optimization,
	  </li>
	  <li class='fragment'>
	    whose results must be accepted with lots of tuning <br> (and a grain of salt).
	  </li>
	</section>
	
	<section>
	  <h3>Hypothesis testing</h3>
	  
	  <li class='fragment'>
	    Hypothesis testing is described well by the name.
	  </li>
	  <li class='fragment'>
	    There are two outcomes&mdash;null and alternative hypotheses.
	  </li>
	  <li class='fragment'>
	    A null hypothesis is the assumed default outcome,
	  </li>
	  <li class='fragment'>
	    e.g., drug X had no effect on the patient's condition,
	  </li>	  
	  <li class='fragment'>
	    and the alternative is the opposite,
	  </li>
	  <li class='fragment'>
	    e.g., drug X had an effect on the patient's condition.
	  </li>	  
	  <li class='fragment'>
	    For acceptance/rejection, a test statistic is measured,
	  </li>
	  <li class='fragment'>
	    in the context of an assumed probability distribution.
	  </li>
	  <li class='fragment'>
	    With probability known, one check a &quot;significance level,&quot;
	  </li>
	  <li class='fragment'>
	    which if/not crossed, results in rejection/acceptance.
	  </li>
	</section>

	<section>
	  <h3>p-values and hacking</h3>
	  
	  <li class='fragment'>
	    p-values describe how likely more-extreme test statistics are.
	  </li>
	  <li class='fragment'>
	    They are interpreted as measures of &quot;statistical significance.&quot;
	  </li>
	  <li class='fragment'>
	    Generally, p-values above 0.05 or 0.1 are unacceptable,
	  </li>
	  <li class='fragment'>
	    and scientific standards hold the p-value up very high.
	  </li>		
	  <li class='fragment'>
	    This means some researchers will ignore low p-values research,
	  </li>
	  <li class='fragment'>
	    or use computational ease to slice data for significance.
	  </li>
	  <li class='fragment'>
	    Meaning results go unreported or tweaked for significance.
	  </li>
	  <li class='fragment'>
	    These practices are called data dredging, or p-hacking.
	  </li>
	</section>
	
	<section>
	  <h3>Required reading:
	    <a href="http://fivethirtyeight.com/features/science-isnt-broken/">p-hacking</a></h3>
	  <center>
	    <img src="./images/science_broken.jpg" alt=" " style="width: 80%;max-height: 100%;object-fit: contain;Float: center" />
	  </center>	  
	  
	</section>
	
	<section>
	  <h3>Machine learning</h3>

	  <li class='fragment'>
	    Machine learning is a branch of artificial intelligence.
	  </li>
	  <li class='fragment'>
	    Focused on data analysis, it is similar to statistics,
	  </li>	  
	  <li class='fragment'>
	    but is rule-based programming that learns from data.
	  </li>
	  <li class='fragment'>
	    Generally, there are supervised and unsupervised algorithms.
	  </li>
	  <li class='fragment'>
	    Supervised algorithms learn from ground-truth, labeled data,
	  </li>
	  <li class='fragment'>
	    while the un-supervised are just processes that follow patterns.
	  </li>
	  <li class='fragment'>
	    Machine learning may, or may not use statistics,
	  </li>
	  <li class='fragment'>
	    and is most focused on algorithm outcome quality,
	  </li>
	  <li class='fragment'>
	    as opposed to theoretical soundness and variable relationships.
	  </li>
	</section>
	
	<section>
	  <h3>Required readings</h3>
	  1) <a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">A visual introduction to machine learning</a>
	  <br>
	  2) <a href="https://www.analyticsvidhya.com/blog/2015/07/difference-machine-learning-statistical-modeling/">Statistics vs. machine learning</a>
	  <center>
	    <a href="http://nkonst.com/machine-learning-explained-simple-words/">
	      <img src="./images/ml-workflow.png" alt=" " style="width: 80%;max-height: 100%;object-fit: contain;Float: center" />
	    </a>
	  </center>	  	  
	</section>	
	
	<section>
	  <h3>Model selection</h3>

	  <li class='fragment'>
	    There are a lot of different kinds of models out there!
	  </li>
	  <li class='fragment'>
	    Choosing the right model starts with knowing what exists.
	  </li>
	  <li class='fragment'>
	    Additionally, exploratory data analysis should be a guide.
	  </li>	  
	  <li class='fragment'>
	    So, selection can occur early on after exploration,
	  </li>	  
	  <li class='fragment'>
	    or, it can be a part of a reported analysis,
	  </li>
	  <li class='fragment'>
	    i.e., from 7 models choose the best-performing for a product.
	  </li>
	  <li class='fragment'>
	    However, performance should not be the only consideration.
	  </li>
	  <br>
	  <ul>
	    <li class='fragment'> Some other selection factors:
	      <ul>
		<li class='fragment'>
		  What model is a good theoretical match for the data?
		</li>		
		<li class='fragment'>
		  How efficiently or quickly does a model run?
		</li>
		<li class='fragment'>
		  How domain-portable is a model?
		</li>
		<li class='fragment'>
		  How difficult is a model to implement?
		</li>
		<li class='fragment'>
		  Will the model scale across multiple machines?
		</li>
		<li class='fragment'>
		  How transparent are a model's inner workings?
		</li>		
	      </ul>
	    </li>
	  </ul>
	</section>

	<section>
	  <h3>Required reading:
	    <a href="http://sebastianraschka.com/faq/docs/model-selection-in-datascience.html">DS model selection</a>
	  </h3>
	</section>

	<section>
	  <h3>The bias-variance tradeoff</h3>

	  <ul>
	    <li class='fragment'> Modeling error can be broken down into three parts:
	      <ul>
		<li class='fragment'>
		  bias error, due to the assumptions made in a model;
		</li>		
		<li class='fragment'>
		  variance error, due to sensitivity of a model on training;
		</li>
		<li class='fragment'>
		  and irreducible error, due to factors unknown, often external.
		</li>
	      </ul>
	    </li>
	  </ul>

	  <br><br>
	  
	  <li class='fragment'>
	    Irreducible error can result from data collection, formation, etc.,
	  </li>
	  <li class='fragment'>
	    but bias and variance are somewhat controllable.
	  </li>
	  <li class='fragment'>
	    These two types of error are linked and  must be balanced;
	  </li>	  
	  <li class='fragment'>
	    when bias error is up, variance error is often down (vice-versa).
	  </li>	  
	  <li class='fragment'>
	    True bias and variance decompositions of error are hard to find,
	  </li>
	  <li class='fragment'>
	    since they would require knowing a &quot;true&quot; target function,
	  </li>
	  <li class='fragment'>
	    but cross-validated training hints at variance error for a model,
	  </li>

	  <li class='fragment'>
	    leaving bias and irreducible errors mixed, but approachable.
	  </li>
	  
	</section>

	<section>
	  <h3>Required reading:
	    <a href="http://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/">Bias-variance tradeoff</a>
	  </h3>
	</section>
	
	<section>
	  <h3>Are models necessary?</h3>

	  <li class='fragment'>
	    A common aphorism in statistics is &quot;<a href="https://en.wikipedia.org/wiki/All_models_are_wrong">all models are wrong</a>.&quot;
	  </li>
	  <li class='fragment'>
	    With data, this is kinda tautological, as noise is ever present.
	  </li>
	  <li class='fragment'>
	    But some have posited that Big Data makes models obsolete!
	  </li>
	  <li class='fragment'>
	    I.e., with enough data, models are not necessary for prediction,
	  </li>
	  <li class='fragment'>
	    e.g., Google doesn't need to know about culture or conventions
	  </li>
	  <li class='fragment'>
	    in order to be able to serve advertisements&mdash;just data!
	  </li>
	  <li class='fragment'>
	    Yeah, but there are different kinds of models,
	  </li>	  
	  <li class='fragment'>
	    e.g., the Internet as a click-through network is an applied model,
	  </li>
	  <li class='fragment'>
	    and this is what makes Google's PageRank the best at search!
	  </li>
	  <li class='fragment'>
	    So, with a grain of salt: Big Data might obviate some models,
	  </li>
	  <li class='fragment'>
	    but more likely, open up opportunities for new alternatives.
	  </li>
	</section>

	<section>
	  <h3>Required reading:
	    <a href="readings/the-end-of-theory.pdf">The end of theory</a>
	  </h3>
	</section>
	
	<section>
	  <h3>Recap</h3>

	  <li class='fragment'>
	    Modeling is heavy on mathematics and statistics.
	  </li>
	  
	  <li class='fragment'>
	    Model selection is guided by many factors,
	  </li>

	  <li class='fragment'>
	    and is preceded by exploratory data analysis.
	  </li>	  

	  <li class='fragment'>
	    Theoretical relevance can make a model highly valuable,
	  </li>	  
	  
	  <li class='fragment'>
	    but sometimes it's all about performance product quality,
	  </li>

	  <li class='fragment'>
	    balancing bias and variance as best possible.
	  </li>
	  
	  <br>
	  <ul>
	    <li class='fragment'> Next week: <a href="ch12.html">Classification</a>
	      <ul>
		<li class='fragment'>
		  How do machines discriminate?
		</li>
		<li class='fragment'>
		  How is machine discrimination evaluated?
		</li>
		<li class='fragment'>
		  What happens when machines make errors?
		</li>		
	      </ul>
	    </li>
	  </ul>

	</section>
	
      </div>

    </div>
    
    <script src="./lib/js/head.min.js"></script>
    <script src="./js/reveal.js"></script>

    <script>

      Reveal.initialize({
      history: true,
      transition: 'none',

      math: {
      // mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
      config: 'TeX-AMS_HTML-full'
      },

      dependencies: [
      { src: './lib/js/classList.js' },
      { src: 'plugin/external/external.js', condition: function() { return !!document.querySelector( '[data-external]' ); } },
      { src: './plugin/math/math.js', async: true }
      ]
      });

    </script>

  </body>
</html>
